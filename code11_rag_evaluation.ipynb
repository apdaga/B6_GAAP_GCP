{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "461743ad",
   "metadata": {},
   "source": [
    "# RAG Evaluation Using RAGAS\n",
    "\n",
    "## Introduction to Evaluation\n",
    "Evaluation in the context of Retrieval-Augmented Generation (RAG) systems involves assessing the performance of both the retrieval component (how well relevant documents are fetched from a knowledge base)\n",
    "and the generation component (how accurate, relevant, and coherent the generated responses are). A RAG system combines a retriever (e.g., a vector store like FAISS) with a language model (e.g., AzureChatOpenAI) to provide contextually informed responses, reducing issues like hallucinations (incorrect or fabricated information).\n",
    "\n",
    "## Why Do We Use Evaluation?\n",
    "- Evaluation is critical for the following reasons:\n",
    "- Quality Assurance: Ensures the RAG system delivers accurate, relevant, and trustworthy responses.\n",
    "- System Improvement: Identifies weaknesses in retrieval (e.g., irrelevant documents) or generation (e.g., unfaithful answers), guiding optimizations like better embeddings or prompt engineering.\n",
    "- Performance Monitoring: Quantifies system performance to track improvements or regressions over time.\n",
    "- Stakeholder Confidence: Provides metrics to demonstrate the system's reliability to stakeholders or end-users.\n",
    "\n",
    "### The RAGAS framework (Retrieval Augmented Generation Assessment) is used to evaluate RAG systems. It provides metrics like:\n",
    "- Faithfulness: Measures if the generated answer is factually grounded in the retrieved context.\n",
    "- Answer Relevancy: Assesses if the answer directly addresses the user's query.\n",
    "- Context Precision: Checks if the retrieved context contains relevant information with minimal noise.\n",
    "- Context Recall: Ensures all necessary information is retrieved (requires ground truth).\n",
    "\n",
    "This notebook sets up a RAG system using AzureChatOpenAI, AzureOpenAIEmbeddings, and FAISS, generates a synthetic test dataset, and evaluates the system using RAGAS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b676455",
   "metadata": {},
   "source": [
    "Loads environment variables (e.g., API keys) from a .env file for secure configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5da1a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pymupdf faiss-cpu ragas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94ee4db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758523879.085412    4698 fork_posix.cc:71] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install rapidfuzz --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f0d1f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embedding_model_name = \"models/gemini-embedding-001\"\n",
    "model_name = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab08bef",
   "metadata": {},
   "source": [
    "\n",
    "Initializes AzureChatOpenAI for response generation and AzureOpenAIEmbeddings for creating document embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db718d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=embedding_model_name)\n",
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(model_name, model_provider=\"google_genai\")\n",
    "\n",
    "\n",
    "dir_path = r\"datasets/supply_chain\"\n",
    "index_path = r\"VectorDB_Chroma/faiss\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f667d3",
   "metadata": {},
   "source": [
    "## Document Loading\n",
    "This section loads PDF documents from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45b7b308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and split 131 document chunks.\n"
     ]
    }
   ],
   "source": [
    "def load_documents():\n",
    "    \"\"\"\n",
    "    Load PDF documents from the specified directory using PyMuPDFLoader.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of loaded documents.\n",
    "    \n",
    "    Raises:\n",
    "        FileNotFoundError: If the directory does not exist.\n",
    "        Exception: For other loading errors.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(dir_path):\n",
    "        raise FileNotFoundError(f\"Directory not found: {dir_path}\")\n",
    "    try:\n",
    "        loader = DirectoryLoader(dir_path, loader_cls=PyMuPDFLoader)\n",
    "        return loader.load()\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "def split_documents(documents):\n",
    "    \"\"\"\n",
    "    Split documents into smaller chunks using RecursiveCharacterTextSplitter.\n",
    "    \n",
    "    Args:\n",
    "        documents (list): List of documents to split.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of document chunks. Returns empty list if no documents.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not documents:\n",
    "            return []\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=200)\n",
    "        return text_splitter.split_documents(documents)\n",
    "    except Exception as e:\n",
    "        print(f\"Error splitting documents: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "# Load and split documents\n",
    "documents = load_documents()\n",
    "documents = split_documents(documents)\n",
    "print(f\"Loaded and split {len(documents)} document chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a0726e",
   "metadata": {},
   "source": [
    "## Vector Store Creation\n",
    "\n",
    "Now splits documents into chunks, and creates a FAISS vector store for retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e80f2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Store created Successfully\n",
      "vector Store saved successfully\n",
      "loading vector Store...\n",
      "loaded successfully\n",
      "<langchain_community.vectorstores.faiss.FAISS object at 0x7dfbdfd31210>\n",
      "Created and loaded new vector store.\n"
     ]
    }
   ],
   "source": [
    "def create_vectorstore(documents):\n",
    "    \"\"\"\n",
    "    Create and save a new FAISS vector store from documents.\n",
    "    \n",
    "    Args:\n",
    "        documents (list): List of document objects to convert to vectors.\n",
    "    \n",
    "    Returns:\n",
    "        None: If successful, else Exception.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(index_path, exist_ok=True)\n",
    "        vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "        print(\"Vector Store created Successfully\")\n",
    "        save_vectorstore(vectorstore)\n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "def save_vectorstore(vectorstore):\n",
    "    \"\"\"\n",
    "    Save the FAISS vector store to the specified path.\n",
    "    \n",
    "    Args:\n",
    "        vectorstore (FAISS): The vector store to save.\n",
    "    \n",
    "    Returns:\n",
    "        None: If successful, else Exception.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        vectorstore.save_local(index_path)\n",
    "        print(\"vector Store saved successfully\")\n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "def load_vectorstore():\n",
    "    \"\"\"\n",
    "    Load an existing FAISS vector store.\n",
    "    \n",
    "    Returns:\n",
    "        FAISS: Loaded vector store, else Exception.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"loading vector Store...\")\n",
    "        vs = FAISS.load_local(index_path, embeddings=embeddings, allow_dangerous_deserialization=True)\n",
    "        print(\"loaded successfully\")\n",
    "        return vs\n",
    "    \n",
    "    except Exception as e:\n",
    "        return e\n",
    "\n",
    "# Load or create vector store\n",
    "if os.path.exists(index_path) and any(os.listdir(index_path)):\n",
    "    vectorstore = load_vectorstore()\n",
    "    vectorstore_retriever = vectorstore.as_retriever(search_kwargs={'k': 5})\n",
    "    print(\"Vector store loaded successfully.\")\n",
    "else:\n",
    "    create_vectorstore(documents)\n",
    "    vectorstore = load_vectorstore()\n",
    "    print(vectorstore)\n",
    "    vectorstore_retriever = vectorstore.as_retriever(search_kwargs={'k': 5})\n",
    "    print(\"Created and loaded new vector store.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b579f6",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "- Document Loading: Uses DirectoryLoader with PyMuPDFLoader to load PDFs from the data directory.\n",
    "- Document Splitting: Splits documents into chunks (500 characters, 200 overlap) for efficient retrieval.\n",
    "- Vector Store: Creates a FAISS index from document embeddings or loads an existing one from the index directory.\n",
    "- Retriever: Configures the vector store as a retriever, fetching the top 5 relevant documents for a query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a257d66b",
   "metadata": {},
   "source": [
    "## RAG Chain Setup\n",
    "This section defines a RAG chain that validates queries, retrieves relevant documents, and generates answers using the AzureChatOpenAI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec1c3a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG Chain Response:\n",
      "*   A network of partners collectively converting a basic commodity (upstream) into a finished product (downstream) valued by end-customers, managing returns at each stage.\n",
      "*   Each partner is responsible for a process that adds value to a product by transforming inputs into outputs.\n",
      "*   Supply chain management involves planning and controlling all processes from raw material production to end-user purchase and recycling.\n",
      "*   It is about planning and controlling all business processes from end-customer to raw material suppliers, linking partners to serve the end-customer's needs.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def validate_query(query):\n",
    "    \"\"\"\n",
    "    Validates a user's query by ensuring it is not empty and has at least 15 characters.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The input query.\n",
    "    \n",
    "    Returns:\n",
    "        str: The query if valid, or an error message if invalid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not query:\n",
    "            return \"Query cannot be empty, enter a valid query.\"\n",
    "        elif len(query) < 15:\n",
    "            return \"Query is too short, enter a valid query.\"\n",
    "        else:\n",
    "            return query\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "def create_rag_chain(query, relevant_documents):\n",
    "    \"\"\"\n",
    "    Creates and executes a RAG chain to answer a query using retrieved documents.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The user query.\n",
    "        relevant_documents (list): List of retrieved document chunks.\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated response or an error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        prompt_template = \"\"\"\n",
    "        Only based on the provided documents, answer the question in points. Do not mention from which document the answer is derived.\n",
    "        Question: {query}\n",
    "        Documents: {docs}\n",
    "        Note: You are a supply chain assistant. If the query is not related to supply chain or the documents do not provide the necessary information, return \"Invalid Query\".\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "        valid_query = validate_query(query)\n",
    "        rag_chain = prompt | llm | StrOutputParser()\n",
    "        return rag_chain.invoke({\"query\": valid_query, \"docs\": relevant_documents})\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Test the RAG chain\n",
    "query = \"What is Supply Chain?\"\n",
    "relevant_documents = vectorstore_retriever.invoke(query)\n",
    "response = create_rag_chain(query, relevant_documents)\n",
    "print(\"RAG Chain Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccf2f98",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "- Query Validation: Ensures the query is non-empty and at least 15 characters long.\n",
    "- RAG Chain: Constructs a prompt that instructs the model to answer in bullet points, using only the retrieved documents, and to return \"Invalid Query\" if the query is unrelated to supply chain or unsupported by the documents.\n",
    "- Execution: Combines the prompt, AzureChatOpenAI model, and string output parser to generate a response.\n",
    "- Test: Runs a sample query to verify the RAG chain's functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc2bbe2",
   "metadata": {},
   "source": [
    "## Generating Synthetic Test Data with RAGAS\n",
    "To evaluate the RAG system, we need a test dataset with questions, answers, contexts, and ground truth. RAGAS's TestsetGenerator can create synthetic data from documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e18d305c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlinesExtractor:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying HeadlinesExtractor: 100%|██████████| 8/8 [00:14<00:00,  1.76s/it]\n",
      "Applying HeadlineSplitter: 100%|██████████| 10/10 [00:00<00:00, 12221.17it/s]\n",
      "Applying SummaryExtractor:   6%|▋         | 1/16 [00:02<00:44,  2.95s/it]Property 'summary' already exists in node 'f8e7c9'. Skipping!\n",
      "Property 'summary' already exists in node 'df0eee'. Skipping!\n",
      "Property 'summary' already exists in node 'd749af'. Skipping!\n",
      "Property 'summary' already exists in node 'f7393c'. Skipping!\n",
      "Property 'summary' already exists in node '11e85c'. Skipping!\n",
      "Property 'summary' already exists in node 'e43394'. Skipping!\n",
      "Applying SummaryExtractor:  81%|████████▏ | 13/16 [00:20<00:03,  1.18s/it]Property 'summary' already exists in node 'f91f57'. Skipping!\n",
      "Property 'summary' already exists in node 'b3371d'. Skipping!\n",
      "Applying SummaryExtractor: 100%|██████████| 16/16 [00:25<00:00,  1.58s/it]\n",
      "Applying CustomNodeFilter: 0it [00:00, ?it/s]\n",
      "Applying EmbeddingExtractor:   6%|▋         | 1/16 [00:02<00:36,  2.40s/it]Property 'summary_embedding' already exists in node 'e43394'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'df0eee'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f91f57'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f7393c'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '11e85c'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'd749af'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f8e7c9'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'b3371d'. Skipping!\n",
      "Applying EmbeddingExtractor: 100%|██████████| 16/16 [00:13<00:00,  1.16it/s]\n",
      "Applying ThemesExtractor: 0it [00:00, ?it/s]\n",
      "Applying NERExtractor: 0it [00:00, ?it/s]\n",
      "Applying CosineSimilarityBuilder: 100%|██████████| 1/1 [00:00<00:00, 105.64it/s]\n",
      "Applying OverlapScoreBuilder: 100%|██████████| 1/1 [00:00<00:00, 2772.18it/s]\n",
      "Generating personas: 100%|██████████| 3/3 [00:06<00:00,  2.30s/it]\n",
      "Generating Scenarios: 100%|██████████| 2/2 [00:23<00:00, 11.95s/it]\n",
      "Generating Samples: 100%|██████████| 3/3 [00:07<00:00,  2.49s/it]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "# Configure the test set generator\n",
    "testset_generator = TestsetGenerator.from_langchain(\n",
    "    llm=llm,\n",
    "    embedding_model=embeddings\n",
    ")\n",
    "\n",
    "# Randomly sample a subset of documents (e.g., 50 out of 902 chunks)\n",
    "sample_size = 10  # Adjust based on your needs\n",
    "random.seed(42)  # For reproducibility\n",
    "sampled_documents = random.sample(documents, min(sample_size, len(documents)))\n",
    "\n",
    "# Generate test dataset with reduced test_size\n",
    "testset = testset_generator.generate_with_langchain_docs(sampled_documents, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6384ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TestsetSample(eval_sample=SingleTurnSample(user_input='Wat iz supply chain manegemnt and how does it impakt end-custmers?', retrieved_contexts=None, reference_contexts=['the conversion of basic commodity into ﬁnished product. At each stage of the\\nconversion, there may be returns which could be reject material from the preced-\\ning ﬁrm, or waste like the ﬁnished can that needs to be recycled.\\nA supply chain is a network of partners who collectively convert a basic commod-\\nity (upstream) into a ﬁnished product (downstream) that is valued by end-cus-\\ntomers, and who manage returns at each stage.\\nEach partner in a supply chain is responsible directly for a process that adds value\\nto a product. A process:\\nTransforms inputs in the form of materials and information into outputs in the\\nform of goods and services.\\nIn the case of the cola can, partners carry out processes such as mining, trans-\\nportation, reﬁning and hot rolling. The cola can has greater value than the baux-\\nite (per kilogram of aluminium).\\nSupply chain management involves planning and controlling all of the processes\\nfrom raw material production to purchase by the end-user to recycling of the\\nused cans. Planning refers to making a plan that deﬁnes how much of each prod-\\nuct should be bought, made, distributed and sold each day, week or month.\\nControlling means keeping to plan – in spite of the many problems that may get\\nin the way. The aim is to coordinate planning and control of each process so that\\nthe needs of the end-customer are met correctly. The deﬁnition of supply chain\\nmanagement used in this book is as follows:\\nPlanning and controlling all of the business processes – from end-customer to raw\\nmaterial suppliers – that link together partners in a supply chain in order to serve\\nthe needs of the end-customer.\\n‘Serve the needs of the end-customer’ has different implications in different con-\\ntexts. In not-for-proﬁt environments such as public health and local govern-\\nment, \\nserving \\nimplies \\n‘continuously \\nimproving’, \\n‘better \\nthan \\nother\\nregions/countries’, ‘best value’ and the like. In the commercial sector, serving\\nimplies ‘better than competition’, ‘better value for money’ and so on. In either\\nsituation, the focus of managing the supply chain as a whole is on integrating the\\nprocesses of supply chain partners, of which the end-customer is the key one. In\\neffect, the end-customer starts the whole process by buying ﬁnished products. It\\nis this behaviour that causes materials to ﬂow through the supply chain\\n(Gattorna, 1998: 2).\\nThe degree to which the end-customer is satisﬁed with the ﬁnished product\\ndepends crucially on the management of material ﬂow and information ﬂow\\nalong the supply chain. If delivery is late, or the product has bits missing, the\\nwhole supply chain is at risk from competitors who can perform the logistics task\\nbetter. Logistics is a vital enabler for supply chain management. We use the fol-\\nlowing deﬁnition of logistics in this book:\\nThe task of coordinating material ﬂow and information ﬂow across the supply\\nchain.\\nLogistics has both strategic (long-term planning) and managerial (short- and'], response=None, multi_responses=None, reference='Supply chain management involves planning and controlling all of the business processes – from end-customer to raw material suppliers – that link together partners in a supply chain in order to serve the needs of the end-customer. The degree to which the end-customer is satisﬁed with the ﬁnished product depends crucially on the management of material ﬂow and information ﬂow along the supply chain.', rubrics=None), synthesizer_name='single_hop_specific_query_synthesizer'),\n",
       " TestsetSample(eval_sample=SingleTurnSample(user_input='How iz logistiks costz representid?', retrieved_contexts=None, reference_contexts=['How can logistics costs be represented?\\n75\\nProfit-making\\nvolume\\nBreak-even\\nvolume\\nLoss-making\\nvolume\\nFixed cost\\nLow variable cost\\nSales revenue\\nLarge contribution\\nper unit\\nO\\nHigh\\nfixed\\ncost\\nCost / Revenue (€)\\nVolume\\nArea of loss\\nArea of profit\\nFigure 3.7\\nBreak-even chart B\\n(Source: Courtesy of Sri Srikanthan)\\nBond SA – a marginal costing example\\nBond SA is planning to manufacture a new product with an initial sales forecast of 3,600\\nunits in the ﬁrst year at a selling price of €800 each. The ﬁnance department has cal-\\nculated that the variable cost for each truck will be €300. The ﬁxed costs for the manu-\\nfacturing facility for the year are €1,500,000. Using the information provided by the\\nsales forecast and the ﬁnance department it is now possible to calculate the planned\\nproﬁt, the contribution and the break-even point for this venture by leveraging the\\nnature of ﬁxed and variable costs. \\nIf Bond plc achieves its sales forecast of 3,600 units then the company will make a\\nplanned proﬁt before tax of €300,000. Crucially the company’s break-even point is\\n3,000 units, at which point Bond plc makes no proﬁt but also no loss, because sales rev-\\nenue (€2,400,000) equals all the variable costs (€900,000) and all the total ﬁxed costs\\nassociated with production process (€1,500,000). Any additional unit sold after this\\npoint will provide Bond with proﬁtable sales revenue. The difference between the\\nplanned proﬁt and the break-even point is called the margin of safety. In the case of\\nBond SA, this equates to 600 units.\\n(Source: Simon Templar, Cranﬁeld)\\nCASE STUDY\\n3.1\\nPlanned proﬁt\\n€\\nPlanned break-even point\\n€\\nSales revenue\\n2,880,000\\nFixed costs\\n1,500,000\\nLess variable costs\\n1,080,000\\nContribution per unit \\nContribution\\n1,800,000\\nSales value – variable cost\\n500\\nLess ﬁxed costs\\n1,500,000\\nBreak-even point (units)\\nProﬁt\\n300,000\\nFixed costs/contribution per unit\\n3,000'], response=None, multi_responses=None, reference='Logistics costs are not explicitly represented in the provided text. The text focuses on representing costs in the context of manufacturing and sales, including fixed costs, variable costs, sales revenue, contribution per unit, break-even point, and profit.', rubrics=None), synthesizer_name='single_hop_specific_query_synthesizer'),\n",
       " TestsetSample(eval_sample=SingleTurnSample(user_input=\"How can a manufacturing firm ensure risk management in the supply chain is not solely the responsibility of a team, and what steps can be taken to create an ongoing, organization-wide focus and effort, especially considering examples like Henkel's approach with risk teams?\", retrieved_contexts=None, reference_contexts=['●training plant management and staff;\\n●report to senior management on risk proﬁles and preparedness.\\nMost important, however, is not to leave risk management in the supply chain\\nsolely the responsibility of a team, but to use the team to create an ongoing\\norganisation-wide focus and effort. Most often teams help plant management and\\nvarious functions in the organisation, instead of telling them what to do. Henkel,\\nthe German consumer goods company for example, has appointed risk teams to\\nwork with various departments in assessing risk. It raises fundamental awareness\\nacross the organisation, and is the basis for developing contingency plans proac-\\ntively.\\n4.7 Corporate social responsibility in the supply chain\\nKey issue: Companies operating international or global supply chains need to\\nincorporate social responsibility into their supply chain design\\nBroadly deﬁned, corporate social responsibility (CSR) in the supply chain deals\\nwith the social and environmental consequences of supply chain operations.\\nMaking a global supply chain environmentally sustainable and socially consid-\\nerate is harder than just doing so for a focal ﬁrm. This is due to global reach and\\nthe fact that multiple companies are involved. As a result, it is harder to assess\\nand improve operating policies across the entire supply chain. Yet this is a key\\nopportunity to bring CSR to life. \\nTwo examples illustrate the challenge:\\n●In 2006 the ship Probo Koala was redirected from Amsterdam to the Côte\\nd’Ivoire where it dumped its waste, leading to the death of several people in\\nthe shore area. Consequently, questions were asked in Europe about the lack\\nof responsibility taken and the approach of turning a blind eye locally.\\n●Nike came under heavy scrutiny from customers in the 1990s for its use of low-\\ncost labour, predominantly in Asia. There were suspicions of use of child\\nlabour, and other unethical labour practices among Nike suppliers. Nike\\nlaunched a comprehensive CSR effort – including the appointment of a Vice\\nPresident for CSR – and now is considered to be a leader for improving supplier\\npractices and for responsible behaviour along the supply chain.\\nCSR has caught both public and political attention, and companies are develop-\\ning approaches that span the spectrum displayed in Figure 4.15 overleaf. Worst\\npractice in CSR is for companies to publish a CSR report and to engage in PR\\nefforts to make the company look responsible, yet hide behind the approach:\\nI can’t see everything in my supply chain that happens on the other side of the\\nglobe in another company, so I can’t manage that. \\nSo not much changes in day-to-day operations – other than telling suppliers that\\nthey ‘need to be responsible for their actions’. \\n132\\nChapter 4 • Managing logistics internationally'], response=None, multi_responses=None, reference='To ensure risk management in the supply chain is not solely the responsibility of a team, the team should be used to create an ongoing organization-wide focus and effort. Most often teams help plant management and various functions in the organization, instead of telling them what to do. Henkel, the German consumer goods company, has appointed risk teams to work with various departments in assessing risk. This raises fundamental awareness across the organization and is the basis for developing contingency plans proactively.', rubrics=None), synthesizer_name='single_hop_specific_query_synthesizer')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab29568b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 3 test cases.\n"
     ]
    }
   ],
   "source": [
    "# Convert test dataset to evaluation format\n",
    "eval_data = {\n",
    "    \"question\": [],\n",
    "    \"answer\": [],\n",
    "    \"contexts\": [],\n",
    "    \"ground_truth\": []\n",
    "}\n",
    "\n",
    "for testcase in testset.samples:\n",
    "    relevant_docs = vectorstore_retriever.invoke(testcase.eval_sample.user_input)\n",
    "    answer = create_rag_chain(testcase.eval_sample.user_input, relevant_docs)\n",
    "    eval_data[\"question\"].append(testcase.eval_sample.user_input)\n",
    "    eval_data[\"answer\"].append(answer)\n",
    "    eval_data[\"contexts\"].append([doc.page_content for doc in relevant_docs])\n",
    "    eval_data[\"ground_truth\"].append(testcase.eval_sample.reference)\n",
    "\n",
    "print(f\"Generated {len(eval_data['question'])} test cases.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221ee10c",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "- TestsetGenerator: Uses AzureChatOpenAI for generating and critiquing test cases, with AzureOpenAIEmbeddings for document embeddings.\n",
    "- Test Data Generation: Creates test cases with a mix of random samples\n",
    "- Evaluation Dataset: For each test case, retrieves relevant documents, generates an answer using the RAG chain, and collects the question, answer, contexts, and ground truth.\n",
    "- Output: Stores the data in a dictionary format suitable for RAGAS evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5536cdd4",
   "metadata": {},
   "source": [
    "## RAG Evaluation with RAGAS\n",
    "This section evaluates the RAG system using RAGAS metrics: faithfulness, answer relevancy, context precision, and context recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ac8b1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4698/3393354811.py:12: DeprecationWarning: LangchainEmbeddingsWrapper is deprecated and will be removed in a future version. Use the modern embedding providers instead: embedding_factory('openai', model='text-embedding-3-small', client=openai_client) or from ragas.embeddings import OpenAIEmbeddings, GoogleEmbeddings, HuggingFaceEmbeddings\n",
      "  evaluator_embeddings = LangchainEmbeddingsWrapper(embeddings)\n",
      "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]Exception raised in Job[5]: IndexError(list index out of range)\n",
      "Exception raised in Job[1]: IndexError(list index out of range)\n",
      "Exception raised in Job[9]: IndexError(list index out of range)\n",
      "Evaluating: 100%|██████████| 12/12 [00:41<00:00,  3.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAGAS Evaluation Results:\n",
      "{'faithfulness': 1.0000, 'answer_relevancy': nan, 'context_precision': 0.9347, 'context_recall': 1.0000}\n"
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall\n",
    "from datasets import Dataset\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "# Convert evaluation data to Hugging Face Dataset\n",
    "eval_dataset = Dataset.from_dict(eval_data)\n",
    "\n",
    "# Wrap AzureChatOpenAI for RAGAS compatibility\n",
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "evaluator_embeddings = LangchainEmbeddingsWrapper(embeddings)\n",
    "\n",
    "# Run evaluation\n",
    "results = evaluate(\n",
    "    dataset=eval_dataset,\n",
    "    metrics=[\n",
    "        faithfulness,       # Checks if the answer is grounded in the context\n",
    "        answer_relevancy,   # Checks if the answer addresses the question\n",
    "        context_precision,  # Checks if retrieved context is relevant\n",
    "        context_recall      # Checks if all necessary information is retrieved\n",
    "    ],\n",
    "    llm=evaluator_llm,\n",
    "    embeddings=evaluator_embeddings,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "# Print evaluation results\n",
    "print(\"RAGAS Evaluation Results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ed496a",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "- Dataset Conversion: Converts the evaluation data into a Hugging Face Dataset for RAGAS.\n",
    "- LLM Wrapper: Wraps AzureChatOpenAI with LangchainLLMWrapper for compatibility with RAGAS.\n",
    "- Metrics: Evaluates the RAG system on:\n",
    "    - Faithfulness: Ensures answers are factually consistent with the context.\n",
    "    - Answer Relevancy: Measures how well answers address the query.\n",
    "    - Context Precision: Assesses the relevance of retrieved documents.\n",
    "    - Context Recall: Checks if all necessary information is retrieved (uses ground truth).\n",
    "- Results: Outputs scores (0 to 1) for each metric, where higher is better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b2a7e5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
